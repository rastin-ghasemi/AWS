## What is CheckSums?

A checksum is used to check the sum (amount) of data to ensure the data integrity of a file .
if data is download and if in-transit data is loss or mangled the checksum determine there is someting wrong with the file.(upload and download)

Etag: is for check content is chenged

- by defual is MD5

**Ex:**
1. **create bucket**
```bash
aws s3 mb s3://name-random
```
2. **create file and upload**
```bash
nano fiel.txt
```
3. **Get checksum of file**
```bash
md5sum file.txt
```
4. **upload the file**
```bash
aws cp file.txt s3://bucket
```
5. **get object details**
```bash
aws s3api head-object --bicket name-bucket --key name-file
``` 
- if we compare it with etag they are the same 

## S3 object prefixes (virtual folder)
s3 object prefixes are string that proceed the objext filename and is part of the objet name.
since allobject in a bucket are stored in flat structured hierarchy, object prefixed allows  for a way to organize , group and filter objects.

a prefix use th forward slash "/" as delimitator to group similar data, similar to directory or subdirectoris.
- prefixed are not true folders.

- the limit the object key name can cot exceed 1024 bytes with the object prefix and the file name combined.
```bash
example:
Object Key: projects/images/logo.png
Prefix: projects/images/
```
**Ex**
1. **create bucket**
```bash
aws s3 mb s3://name
```
2. **Create folder**
```bash
aws s3api put-object --bucket="name" --key="image/"
```
3. **List Objects by Prefix**
```bash
# List all objects with prefix
aws s3api list-objects-v2 \
  --bucket my-bucket \
  --prefix "projects/"

# List with pagination (for many objects)
aws s3api list-objects-v2 \
  --bucket my-bucket \
  --prefix "projects/" \
  --max-items 100 \
  --starting-token "nextToken"
```
3. **Copy/Move Objects by Prefix**
```bash
# Copy all objects with prefix
aws s3 cp s3://source-bucket/projects/ s3://dest-bucket/projects/ \
  --recursive

# Sync prefixes
aws s3 sync s3://source-bucket/projects/ s3://dest-bucket/projects/
```

4. **Delete Objects by Prefix**
```bash
# Delete all objects with prefix
aws s3 rm s3://my-bucket/projects/ --recursive

# More controlled deletion
aws s3api list-objects-v2 \
  --bucket my-bucket \
  --prefix "projects/temp/" \
  --query "Contents[].Key" \
  --output text | xargs -I {} aws s3 rm s3://my-bucket/{} # xargs -I {}: For each line of input, replace {} with the object key

```

## S3 metadata
Amazon S3 metadata provides additional information about your objects. There are two types: system-defined (automatically created by AWS) and user-defined (custom metadata you add).

## 1. System-Defined Metadata (Auto-generated by AWS)
```bash
Metadata Key	Description	Example
Content-Type	MIME type of object	text/html, image/jpeg
Content-Length	Object size in bytes	1024
Last-Modified	Last modification timestamp	Wed, 01 Jan 2023 12:00:00 GMT
ETag	Object hash/identifier	"d41d8cd98f00b204e9800998ecf8427e"
StorageClass	S3 storage class	STANDARD, GLACIER
ServerSideEncryption	Encryption type	AES256, aws:kms
```

## 2. User-Defined Metadata (Custom Key-Value Pairs)
You can add your own metadata with x-amz-meta- prefix:
```bash
# Upload file with custom metadata
aws s3 cp file.txt s3://my-bucket/file.txt \
  --metadata "author=john,project=website,environment=production"

# Or using s3api for more control
aws s3api put-object \
  --bucket my-bucket \
  --key file.txt \
  --body file.txt \
  --metadata '{"department": "marketing", "version": "2.1"}'
```
**Metadata Naming Rules:**
- Prefix: Must start with x-amz-meta- (added automatically)

- Keys: Case-insensitive

- Values: String data only

- Size limit: 2KB total for all metadata

## Viewing Metadata
```bash
# View all metadata (system + custom)
aws s3api head-object \
  --bucket my-bucket \
  --key file.txt

# View specific metadata fields
aws s3api head-object \
  --bucket my-bucket \
  --key file.txt \
  --query '{ContentType: ContentType, Size: ContentLength, Metadata: Metadata}'
```

## WORM (Write Once, Read Many) in Amazon S3
WORM is a data governance model that prevents objects from being modified or deleted for a specified retention period. In AWS S3, this is implemented through S3 Object Lock.

**What is WORM?**
- Write Once: Data can be written once but not modified

- Read Many: Data can be read multiple times

- No Deletes: Data cannot be deleted until retention period expires

## AWS Implementation: S3 Object Lock
prevent od deletion of object
- fixed period time
or
- permanent
1. **Enable Object Lock (Bucket-level setting)**
```bash
# Must be enabled when creating bucket (cannot be added later)
aws s3api create-bucket \
  --bucket my-worm-bucket \
  --object-lock-enabled-for-bucket
```
## s3  bucket URI
the s3 bucket URI (uniform resource identifier) is a way to reference the address of s3 bucket and s3 object
**EX**
```bash
s3://name/image.jpg
```
## Amazon S3 Request Styles: Path vs Virtual Hosted
Amazon S3 supports two different URL styles for accessing buckets and objects. Understanding these is crucial for proper configuration and troubleshooting.

1. **Path-Style Requests (Legacy)**

- Format: https://s3.region.amazonaws.com/bucket-name/key-name

Examples:
```bash
# Access bucket
https://s3.us-east-1.amazonaws.com/my-bucket

# Access object
https://s3.us-east-1.amazonaws.com/my-bucket/folder/file.txt
```

**Characteristics:**

✅ Works with all bucket names (including dots and special characters)

✅ No DNS compatibility requirements

❌ Deprecated by AWS (being phased out)

❌ Doesn't work with HTTPS+SSL wildcard certificates

2. **Virtual Hosted-Style Requests (Modern)**

- Format: https://bucket-name.s3.region.amazonaws.com/key-name

**Examples:**

```bash
# Access bucket
https://my-bucket.s3.us-east-1.amazonaws.com

# Access object  
https://my-bucket.s3.us-east-1.amazonaws.com/folder/file.txt

# With region-specific endpoint
https://my-bucket.s3-us-east-1.amazonaws.com/folder/file.txt
```

**Characteristics:**

✅ Recommended by AWS

✅ Better SSL/TLS support (works with wildcard certificates)

✅ Required for some newer AWS features

❌ Requires DNS-compliant bucket names (no underscores, uppercase letters, or special characters)

## How to Force a Specific Style
**AWS CLI Configuration:**
```bash
# Use virtual hosted-style (default)
aws configure set default.s3.use_accelerate_endpoint false
aws configure set default.s3.addressing_style virtual

# Force path-style (not recommended)
aws configure set default.s3.addressing_style path
```

## Amazon S3 Storage Classes
Amazon S3 offers multiple storage classes designed for different use cases based on access patterns, durability, and cost requirements.
**change storage class CLI**
```bash
# Use virtual hosted-style (default)
aws configure set default.s3.use_accelerate_endpoint false
aws configure set default.s3.addressing_style virtual

# Force path-style (not recommended)
aws configure set default.s3.addressing_style path
```